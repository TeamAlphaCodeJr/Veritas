{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26351676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas==1.5.3 in c:\\users\\harih\\desktop\\files\\programming\\python\\importantprograms\\school and hackathons\\veritas\\veritas\\venv\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: numpy==1.26.4 in c:\\users\\harih\\desktop\\files\\programming\\python\\importantprograms\\school and hackathons\\veritas\\veritas\\venv\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn==1.2.2 in c:\\users\\harih\\desktop\\files\\programming\\python\\importantprograms\\school and hackathons\\veritas\\veritas\\venv\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: shap==0.41.0 in c:\\users\\harih\\desktop\\files\\programming\\python\\importantprograms\\school and hackathons\\veritas\\veritas\\venv\\lib\\site-packages (0.41.0)\n",
      "Requirement already satisfied: matplotlib==3.7.1 in c:\\users\\harih\\desktop\\files\\programming\\python\\importantprograms\\school and hackathons\\veritas\\veritas\\venv\\lib\\site-packages (3.7.1)\n",
      "Requirement already satisfied: joblib==1.2.0 in c:\\users\\harih\\desktop\\files\\programming\\python\\importantprograms\\school and hackathons\\veritas\\veritas\\venv\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\harih\\desktop\\files\\programming\\python\\importantprograms\\school and hackathons\\veritas\\veritas\\venv\\lib\\site-packages (from pandas==1.5.3) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\harih\\desktop\\files\\programming\\python\\importantprograms\\school and hackathons\\veritas\\veritas\\venv\\lib\\site-packages (from pandas==1.5.3) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\harih\\desktop\\files\\programming\\python\\importantprograms\\school and hackathons\\veritas\\veritas\\venv\\lib\\site-packages (from scikit-learn==1.2.2) (1.16.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\harih\\desktop\\files\\programming\\python\\importantprograms\\school and hackathons\\veritas\\veritas\\venv\\lib\\site-packages (from scikit-learn==1.2.2) (3.6.0)\n",
      "Requirement already satisfied: tqdm>4.25.0 in c:\\users\\harih\\desktop\\files\\programming\\python\\importantprograms\\school and hackathons\\veritas\\veritas\\venv\\lib\\site-packages (from shap==0.41.0) (4.67.1)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\harih\\desktop\\files\\programming\\python\\importantprograms\\school and hackathons\\veritas\\veritas\\venv\\lib\\site-packages (from shap==0.41.0) (25.0)\n",
      "Requirement already satisfied: slicer==0.0.7 in c:\\users\\harih\\desktop\\files\\programming\\python\\importantprograms\\school and hackathons\\veritas\\veritas\\venv\\lib\\site-packages (from shap==0.41.0) (0.0.7)\n",
      "Requirement already satisfied: numba in c:\\users\\harih\\desktop\\files\\programming\\python\\importantprograms\\school and hackathons\\veritas\\veritas\\venv\\lib\\site-packages (from shap==0.41.0) (0.62.1)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\harih\\desktop\\files\\programming\\python\\importantprograms\\school and hackathons\\veritas\\veritas\\venv\\lib\\site-packages (from shap==0.41.0) (3.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\harih\\desktop\\files\\programming\\python\\importantprograms\\school and hackathons\\veritas\\veritas\\venv\\lib\\site-packages (from matplotlib==3.7.1) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\harih\\desktop\\files\\programming\\python\\importantprograms\\school and hackathons\\veritas\\veritas\\venv\\lib\\site-packages (from matplotlib==3.7.1) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\harih\\desktop\\files\\programming\\python\\importantprograms\\school and hackathons\\veritas\\veritas\\venv\\lib\\site-packages (from matplotlib==3.7.1) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\harih\\desktop\\files\\programming\\python\\importantprograms\\school and hackathons\\veritas\\veritas\\venv\\lib\\site-packages (from matplotlib==3.7.1) (1.4.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\harih\\desktop\\files\\programming\\python\\importantprograms\\school and hackathons\\veritas\\veritas\\venv\\lib\\site-packages (from matplotlib==3.7.1) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\harih\\desktop\\files\\programming\\python\\importantprograms\\school and hackathons\\veritas\\veritas\\venv\\lib\\site-packages (from matplotlib==3.7.1) (3.2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\harih\\desktop\\files\\programming\\python\\importantprograms\\school and hackathons\\veritas\\veritas\\venv\\lib\\site-packages (from python-dateutil>=2.8.1->pandas==1.5.3) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\harih\\desktop\\files\\programming\\python\\importantprograms\\school and hackathons\\veritas\\veritas\\venv\\lib\\site-packages (from tqdm>4.25.0->shap==0.41.0) (0.4.6)\n",
      "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in c:\\users\\harih\\desktop\\files\\programming\\python\\importantprograms\\school and hackathons\\veritas\\veritas\\venv\\lib\\site-packages (from numba->shap==0.41.0) (0.45.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas==1.5.3 numpy==1.26.4 scikit-learn==1.2.2 shap==0.41.0 matplotlib==3.7.1 joblib==1.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08feb38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb67df1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f327e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools in c:\\users\\harih\\desktop\\files\\programming\\python\\importantprograms\\school and hackathons\\veritas\\veritas\\venv\\lib\\site-packages (80.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install setuptools\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5867e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dadd0d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b744cfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring...\n"
     ]
    }
   ],
   "source": [
    "print(\"Configuring...\")\n",
    "DATA_PATH = \"data/dataset.csv\"\n",
    "TARGET = \"FAKE\"\n",
    "RANDOM_STATE = 42\n",
    "N_SPLITS = 5\n",
    "RESULTS_DIR = \"model_results/classifiers\"\n",
    "MODELS_DIR = \"models/classifiers\"\n",
    "EXCLUDED_COLS = [\"time\"]\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f66ed59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (10000, 5)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"Data shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7221d6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared features (title only, capped to 10 TF-IDF features): X=(10000, 9), X_scaled=(10000, 9)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Use only the title and cap TF-IDF features to 10\n",
    "if \"title\" not in df.columns:\n",
    "    raise KeyError(\"Column 'title' not found in dataframe\")\n",
    "\n",
    "vectorizer_title = TfidfVectorizer(max_features=10, ngram_range=(1,2), stop_words='english')\n",
    "X_title_tfidf = vectorizer_title.fit_transform(df['title'].astype(str))\n",
    "\n",
    "# Choose SVD components (<=10, at least 1)\n",
    "n_comp_title = max(1, min(10, X_title_tfidf.shape[1] - 1))\n",
    "svd_title = TruncatedSVD(n_components=n_comp_title, random_state=RANDOM_STATE)\n",
    "X_title_reduced = svd_title.fit_transform(X_title_tfidf)\n",
    "\n",
    "X = pd.DataFrame(X_title_reduced, index=df.index, columns=[f\"svd_title_{i}\" for i in range(X_title_reduced.shape[1])])\n",
    "\n",
    "y = df[TARGET]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns, index=X.index)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "results = {}\n",
    "\n",
    "print(f\"Prepared features (title only, capped to 10 TF-IDF features): X={X.shape}, X_scaled={X_scaled.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba44554a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_results(model, use_scaled=False):\n",
    "    X_data = X_scaled if use_scaled else X\n",
    "    accuracy = cross_val_score(model, X_data, y, cv=cv, scoring=\"accuracy\")\n",
    "    precision = cross_val_score(model, X_data, y, cv=cv, scoring=\"precision\")\n",
    "    recall = cross_val_score(model, X_data, y, cv=cv, scoring=\"recall\")\n",
    "    f1 = 2 / (precision ** -1 + recall ** -1)\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d368626",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pipeline = Pipeline([\n",
    "    (\"svm\", SVC(probability=True))  # Removed StandardScaler since we pre-scaled\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"svm__kernel\": [\"linear\", \"rbf\", \"poly\", \"sigmoid\"],\n",
    "    \"svm__C\": [0.1, 1, 10],\n",
    "    \"svm__gamma\": [\"scale\", \"auto\"]\n",
    "}\n",
    "\n",
    "grid_svm = GridSearchCV(svm_pipeline, param_grid, cv=cv, scoring=\"accuracy\", n_jobs=-1)\n",
    "grid_svm.fit(X_scaled, y)  # Use scaled data\n",
    "\n",
    "svm_best = grid_svm.best_estimator_\n",
    "svm_acc, svm_prec, svm_rec, svm_f1 = return_results(svm_best, use_scaled=True)\n",
    "\n",
    "print(\"SVM Best Params:\", grid_svm.best_params_)\n",
    "print(\"SVM Accuracy: %.4f ± %.4f\" % (svm_acc.mean(), svm_acc.std()))\n",
    "print(\"SVM Precision: %.4f ± %.4f\" % (svm_prec.mean(), svm_prec.std()))\n",
    "print(\"SVM Recall: %.4f ± %.4f\" % (svm_rec.mean(), svm_rec.std()))\n",
    "print(\"SVM F1 Score: %.4f ± %.4f\" % (svm_f1.mean(), svm_f1.std()))\n",
    "\n",
    "joblib.dump(svm_best, os.path.join(MODELS_DIR, \"svm_model.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f28b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Best Params: {'knn__metric': 'manhattan', 'knn__n_neighbors': 5, 'knn__weights': 'distance'}\n",
      "KNN Accuracy: 0.9802 ± 0.0031\n",
      "KNN Precision: 0.9766 ± 0.0038\n",
      "KNN Recall: 0.9598 ± 0.0075\n",
      "KNN F1 Score: 0.9681 ± 0.0050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/classifiers\\\\knn_model.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_pipeline = Pipeline([\n",
    "    (\"knn\", KNeighborsClassifier())  # Removed StandardScaler since we pre-scaled\n",
    "])\n",
    "\n",
    "param_grid_knn = {\n",
    "    \"knn__n_neighbors\": [3, 5, 7, 9],\n",
    "    \"knn__weights\": [\"uniform\", \"distance\"],\n",
    "    \"knn__metric\": [\"euclidean\", \"manhattan\"]\n",
    "}\n",
    "\n",
    "grid_knn = GridSearchCV(knn_pipeline, param_grid_knn, cv=cv, scoring=\"accuracy\", n_jobs=-1)\n",
    "grid_knn.fit(X_scaled, y)  # Use scaled data\n",
    "\n",
    "knn_best = grid_knn.best_estimator_\n",
    "knn_acc, knn_prec, knn_rec, knn_f1 = return_results(knn_best, use_scaled=True)\n",
    "\n",
    "print(\"KNN Best Params:\", grid_knn.best_params_)\n",
    "print(\"KNN Accuracy: %.4f ± %.4f\" % (knn_acc.mean(), knn_acc.std()))\n",
    "print(\"KNN Precision: %.4f ± %.4f\" % (knn_prec.mean(), knn_prec.std()))\n",
    "print(\"KNN Recall: %.4f ± %.4f\" % (knn_rec.mean(), knn_rec.std()))\n",
    "print(\"KNN F1 Score: %.4f ± %.4f\" % (knn_f1.mean(), knn_f1.std()))\n",
    "\n",
    "joblib.dump(knn_best, os.path.join(MODELS_DIR, \"knn_model.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c57df24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.9782 ± 0.0038\n",
      "Decision Tree Precision: 0.9657 ± 0.0109\n",
      "Decision Tree Recall: 0.9649 ± 0.0073\n",
      "Decision Tree F1 Score: 0.9652 ± 0.0060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/classifiers\\\\decision_tree_model.pkl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt_acc, dt_prec, dt_rec, dt_f1 = return_results(dt)\n",
    "\n",
    "print(\"Decision Tree Accuracy: %.4f ± %.4f\" % (dt_acc.mean(), dt_acc.std()))\n",
    "print(\"Decision Tree Precision: %.4f ± %.4f\" % (dt_prec.mean(), dt_prec.std()))\n",
    "print(\"Decision Tree Recall: %.4f ± %.4f\" % (dt_rec.mean(), dt_rec.std()))\n",
    "print(\"Decision Tree F1 Score: %.4f ± %.4f\" % (dt_f1.mean(), dt_f1.std()))\n",
    "\n",
    "dt.fit(X, y)\n",
    "joblib.dump(dt, os.path.join(MODELS_DIR, \"decision_tree_model.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfcf355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\harih\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\harih\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\harih\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\harih\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from xgboost) (1.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9034e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Best Params: {'xgb__colsample_bytree': 0.8, 'xgb__learning_rate': 0.1, 'xgb__max_depth': 6, 'xgb__n_estimators': 200, 'xgb__subsample': 0.8}\n",
      "XGBoost Results:\n",
      "  Accuracy: 0.9904 ± 0.0019\n",
      "  Precision: 0.9897 ± 0.0024\n",
      "  Recall: 0.9796 ± 0.0048\n",
      "  F1-Score: 0.9846 ± 0.0030\n",
      "[LightGBM] [Info] Number of positive: 1568, number of negative: 3432\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000679 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 542\n",
      "[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313600 -> initscore=-0.783342\n",
      "[LightGBM] [Info] Start training from score -0.783342\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1255, number of negative: 2745\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 537\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313750 -> initscore=-0.782646\n",
      "[LightGBM] [Info] Start training from score -0.782646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1255, number of negative: 2745\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000402 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 542\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313750 -> initscore=-0.782646\n",
      "[LightGBM] [Info] Start training from score -0.782646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1254, number of negative: 2746\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000178 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 541\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313500 -> initscore=-0.783807\n",
      "[LightGBM] [Info] Start training from score -0.783807\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1254, number of negative: 2746\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000201 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 539\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313500 -> initscore=-0.783807\n",
      "[LightGBM] [Info] Start training from score -0.783807\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1254, number of negative: 2746\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 538\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313500 -> initscore=-0.783807\n",
      "[LightGBM] [Info] Start training from score -0.783807\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1255, number of negative: 2745\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 537\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313750 -> initscore=-0.782646\n",
      "[LightGBM] [Info] Start training from score -0.782646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1255, number of negative: 2745\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000379 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 542\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313750 -> initscore=-0.782646\n",
      "[LightGBM] [Info] Start training from score -0.782646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1254, number of negative: 2746\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000422 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 541\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313500 -> initscore=-0.783807\n",
      "[LightGBM] [Info] Start training from score -0.783807\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1254, number of negative: 2746\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 539\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313500 -> initscore=-0.783807\n",
      "[LightGBM] [Info] Start training from score -0.783807\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1254, number of negative: 2746\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000429 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 538\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313500 -> initscore=-0.783807\n",
      "[LightGBM] [Info] Start training from score -0.783807\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1255, number of negative: 2745\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 537\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313750 -> initscore=-0.782646\n",
      "[LightGBM] [Info] Start training from score -0.782646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1255, number of negative: 2745\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000427 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 542\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313750 -> initscore=-0.782646\n",
      "[LightGBM] [Info] Start training from score -0.782646\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1254, number of negative: 2746\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022922 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 541\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313500 -> initscore=-0.783807\n",
      "[LightGBM] [Info] Start training from score -0.783807\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1254, number of negative: 2746\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 539\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313500 -> initscore=-0.783807\n",
      "[LightGBM] [Info] Start training from score -0.783807\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 1254, number of negative: 2746\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 538\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313500 -> initscore=-0.783807\n",
      "[LightGBM] [Info] Start training from score -0.783807\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM Best Params: {'lgb__colsample_bytree': 0.8, 'lgb__learning_rate': 0.1, 'lgb__n_estimators': 200, 'lgb__num_leaves': 63, 'lgb__subsample': 0.8}\n",
      "LightGBM Results:\n",
      "  Accuracy: 0.9912 ± 0.0017\n",
      "  Precision: 0.9910 ± 0.0024\n",
      "  Recall: 0.9809 ± 0.0041\n",
      "  F1-Score: 0.9859 ± 0.0028\n",
      "[LightGBM] [Info] Number of positive: 1568, number of negative: 3432\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 542\n",
      "[LightGBM] [Info] Number of data points in the train set: 5000, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313600 -> initscore=-0.783342\n",
      "[LightGBM] [Info] Start training from score -0.783342\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/classifiers\\\\lightgbm_model.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# --- XGBoost ---\n",
    "xgb_pipeline = Pipeline([(\"xgb\", XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=RANDOM_STATE))])\n",
    "\n",
    "param_grid_xgb = {\n",
    "    \"xgb__n_estimators\": [100, 200],\n",
    "    \"xgb__max_depth\": [3, 6],\n",
    "    \"xgb__learning_rate\": [0.01, 0.1],\n",
    "    \"xgb__subsample\": [0.8, 1.0],\n",
    "    \"xgb__colsample_bytree\": [0.8, 1.0],\n",
    "}\n",
    "\n",
    "grid_xgb = GridSearchCV(xgb_pipeline, param_grid_xgb, cv=cv, scoring=\"accuracy\", n_jobs=-1)\n",
    "grid_xgb.fit(X, y)\n",
    "\n",
    "xgb_best = grid_xgb.best_estimator_\n",
    "xgb_acc, xgb_prec, xgb_rec, xgb_f1 = return_results(xgb_best)\n",
    "\n",
    "print(\"XGBoost Best Params:\", grid_xgb.best_params_)\n",
    "print(\"XGBoost Results:\")\n",
    "print(\"  Accuracy: %.4f ± %.4f\" % (xgb_acc.mean(), xgb_acc.std()))\n",
    "print(\"  Precision: %.4f ± %.4f\" % (xgb_prec.mean(), xgb_prec.std()))\n",
    "print(\"  Recall: %.4f ± %.4f\" % (xgb_rec.mean(), xgb_rec.std()))\n",
    "print(\"  F1-Score: %.4f ± %.4f\" % (xgb_f1.mean(), xgb_f1.std()))\n",
    "\n",
    "xgb_best.fit(X, y)\n",
    "joblib.dump(xgb_best, os.path.join(MODELS_DIR, \"xgboost_model.pkl\"))\n",
    "\n",
    "# --- LightGBM ---\n",
    "lgb_pipeline = Pipeline([(\"lgb\", LGBMClassifier(random_state=RANDOM_STATE))])\n",
    "\n",
    "param_grid_lgb = {\n",
    "    \"lgb__n_estimators\": [100, 200],\n",
    "    \"lgb__num_leaves\": [31, 63],\n",
    "    \"lgb__learning_rate\": [0.01, 0.1],\n",
    "    \"lgb__subsample\": [0.8, 1.0],\n",
    "    \"lgb__colsample_bytree\": [0.8, 1.0],\n",
    "}\n",
    "\n",
    "grid_lgb = GridSearchCV(lgb_pipeline, param_grid_lgb, cv=cv, scoring=\"accuracy\", n_jobs=-1)\n",
    "grid_lgb.fit(X, y)\n",
    "\n",
    "lgb_best = grid_lgb.best_estimator_\n",
    "lgb_acc, lgb_prec, lgb_rec, lgb_f1 = return_results(lgb_best)\n",
    "\n",
    "print(\"LightGBM Best Params:\", grid_lgb.best_params_)\n",
    "print(\"LightGBM Results:\")\n",
    "print(\"  Accuracy: %.4f ± %.4f\" % (lgb_acc.mean(), lgb_acc.std()))\n",
    "print(\"  Precision: %.4f ± %.4f\" % (lgb_prec.mean(), lgb_prec.std()))\n",
    "print(\"  Recall: %.4f ± %.4f\" % (lgb_rec.mean(), lgb_rec.std()))\n",
    "print(\"  F1-Score: %.4f ± %.4f\" % (lgb_f1.mean(), lgb_f1.std()))\n",
    "\n",
    "lgb_best.fit(X, y)\n",
    "joblib.dump(lgb_best, os.path.join(MODELS_DIR, \"lightgbm_model.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc604cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost AUROC: 1.0000\n",
      "LightGBM AUROC: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Predict probabilities (positive class) and compute AUROC\n",
    "xgb_probs = xgb_best.predict_proba(X)[:, 1]\n",
    "lgb_probs = lgb_best.predict_proba(X)[:, 1]\n",
    "\n",
    "xgb_auc = roc_auc_score(y, xgb_probs)\n",
    "lgb_auc = roc_auc_score(y, lgb_probs)\n",
    "\n",
    "print(f\"XGBoost AUROC: {xgb_auc:.4f}\")\n",
    "print(f\"LightGBM AUROC: {lgb_auc:.4f}\")\n",
    "\n",
    "# store results if needed\n",
    "results.update({\"xgb_auroc\": xgb_auc, \"lgb_auroc\": lgb_auc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f785f6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.7457 ± 0.0054\n",
      "Random Forest Precision: 0.8095 ± 0.0742\n",
      "Random Forest Recall: 0.6596 ± 0.0699\n",
      "Random Forest F1 Score: 0.7200 ± 0.0235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/classifiers\\\\random_forest_model.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42, n_estimators=200)\n",
    "rf_acc, rf_prec, rf_rec, rf_f1 = return_results(rf)\n",
    "\n",
    "print(\"Random Forest Accuracy: %.4f ± %.4f\" % (rf_acc.mean(), rf_acc.std()))\n",
    "print(\"Random Forest Precision: %.4f ± %.4f\" % (rf_prec.mean(), rf_prec.std()))\n",
    "print(\"Random Forest Recall: %.4f ± %.4f\" % (rf_rec.mean(), rf_rec.std()))\n",
    "print(\"Random Forest F1 Score: %.4f ± %.4f\" % (rf_f1.mean(), rf_f1.std()))\n",
    "\n",
    "rf.fit(X, y)\n",
    "joblib.dump(rf, os.path.join(MODELS_DIR, \"random_forest_model.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0291006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7658 ± 0.0071\n",
      "Logistic Regression Precision: 0.6888 ± 0.0254\n",
      "Logistic Regression Recall: 0.4643 ± 0.0203\n",
      "Logistic Regression F1 Score: 0.5541 ± 0.0133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/classifiers\\\\logistic_regression_model.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_pipeline = Pipeline([\n",
    "    (\"logreg\", LogisticRegression(max_iter=1000, solver=\"liblinear\"))  # Removed StandardScaler since we pre-scaled\n",
    "])\n",
    "\n",
    "logreg_acc, logreg_prec, logreg_rec, logreg_f1 = return_results(logreg_pipeline, use_scaled=True)\n",
    "\n",
    "print(\"Logistic Regression Accuracy: %.4f ± %.4f\" % (logreg_acc.mean(), logreg_acc.std()))\n",
    "print(\"Logistic Regression Precision: %.4f ± %.4f\" % (logreg_prec.mean(), logreg_prec.std()))\n",
    "print(\"Logistic Regression Recall: %.4f ± %.4f\" % (logreg_rec.mean(), logreg_rec.std()))\n",
    "print(\"Logistic Regression F1 Score: %.4f ± %.4f\" % (logreg_f1.mean(), logreg_f1.std()))\n",
    "\n",
    "logreg_pipeline.fit(X_scaled, y)\n",
    "joblib.dump(logreg_pipeline, os.path.join(MODELS_DIR, \"logistic_regression_model.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bf57e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM:\n",
      "  Accuracy: 0.9656 ± 0.0047\n",
      "  Precision: 0.9458 ± 0.0080\n",
      "  Recall: 0.9445 ± 0.0127\n",
      "  F1-Score: 0.9451 ± 0.0078\n",
      "\n",
      "KNN:\n",
      "  Accuracy: 0.9802 ± 0.0031\n",
      "  Precision: 0.9766 ± 0.0038\n",
      "  Recall: 0.9598 ± 0.0075\n",
      "  F1-Score: 0.9681 ± 0.0050\n",
      "\n",
      "Decision Tree:\n",
      "  Accuracy: 0.9782 ± 0.0038\n",
      "  Precision: 0.9657 ± 0.0109\n",
      "  Recall: 0.9649 ± 0.0073\n",
      "  F1-Score: 0.9652 ± 0.0060\n",
      "\n",
      "Random Forest:\n",
      "  Accuracy: 0.9888 ± 0.0012\n",
      "  Precision: 0.9909 ± 0.0047\n",
      "  Recall: 0.9732 ± 0.0043\n",
      "  F1-Score: 0.9820 ± 0.0019\n",
      "\n",
      "Logistic Regression:\n",
      "  Accuracy: 0.7658 ± 0.0071\n",
      "  Precision: 0.6888 ± 0.0254\n",
      "  Recall: 0.4643 ± 0.0203\n",
      "  F1-Score: 0.5541 ± 0.0133\n",
      "\n",
      "Cox Proportional Hazards:\n",
      "  Concordance Index: 0.7545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model_results/classifiers\\\\model_accuracies.pkl']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save Accuracy Results\n",
    "results = {\n",
    "    \"SVM\": {\"Accuracy\": (svm_acc.mean(), svm_acc.std()),\n",
    "            \"Precision\": (svm_prec.mean(), svm_prec.std()),\n",
    "            \"Recall\": (svm_rec.mean(), svm_rec.std()),\n",
    "            \"F1 Score\": (svm_f1.mean(), svm_f1.std())},\n",
    "    \"KNN\": {\"Accuracy\": (knn_acc.mean(), knn_acc.std()),\n",
    "            \"Precision\": (knn_prec.mean(), knn_prec.std()),\n",
    "            \"Recall\": (knn_rec.mean(), knn_rec.std()),\n",
    "            \"F1 Score\": (knn_f1.mean(), knn_f1.std())},\n",
    "    \"Decision Tree\": {\"Accuracy\": (dt_acc.mean(), dt_acc.std()),\n",
    "                     \"Precision\": (dt_prec.mean(), dt_prec.std()),\n",
    "                     \"Recall\": (dt_rec.mean(), dt_rec.std()),\n",
    "                     \"F1 Score\": (dt_f1.mean(), dt_f1.std())},\n",
    "    \"Random Forest\": {\"Accuracy\": (rf_acc.mean(), rf_acc.std()),\n",
    "                     \"Precision\": (rf_prec.mean(), rf_prec.std()),\n",
    "                     \"Recall\": (rf_rec.mean(), rf_rec.std()),\n",
    "                     \"F1 Score\": (rf_f1.mean(), rf_f1.std())},\n",
    "    \"Logistic Regression\": {\"Accuracy\": (logreg_acc.mean(), logreg_acc.std()),\n",
    "                           \"Precision\": (logreg_prec.mean(), logreg_prec.std()),\n",
    "                           \"Recall\": (logreg_rec.mean(), logreg_rec.std()),\n",
    "                           \"F1 Score\": (logreg_f1.mean(), logreg_f1.std())},\n",
    "    \"Cox Proportional Hazards\": (c_index, 0)  # Concordance index doesn't have std deviation\n",
    "}\n",
    "\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    if type(metrics) != dict:\n",
    "        print(f\"  Concordance Index: {metrics[0]:.4f}\")\n",
    "    else:\n",
    "        print(f\"  Accuracy: {metrics['Accuracy'][0]:.4f} ± {metrics['Accuracy'][1]:.4f}\")\n",
    "        print(f\"  Precision: {metrics['Precision'][0]:.4f} ± {metrics['Precision'][1]:.4f}\")\n",
    "        print(f\"  Recall: {metrics['Recall'][0]:.4f} ± {metrics['Recall'][1]:.4f}\")\n",
    "        print(f\"  F1-Score: {metrics['F1 Score'][0]:.4f} ± {metrics['F1 Score'][1]:.4f}\")\n",
    "\n",
    "joblib.dump(results, os.path.join(RESULTS_DIR, \"model_accuracies.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f79184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lifelines in c:\\users\\harih\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.30.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\harih\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from lifelines) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\harih\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from lifelines) (1.12.0)\n",
      "Requirement already satisfied: pandas>=2.1 in c:\\users\\harih\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from lifelines) (2.2.1)\n",
      "Requirement already satisfied: matplotlib>=3.0 in c:\\users\\harih\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from lifelines) (3.8.3)\n",
      "Requirement already satisfied: autograd>=1.5 in c:\\users\\harih\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from lifelines) (1.8.0)\n",
      "Requirement already satisfied: autograd-gamma>=0.3 in c:\\users\\harih\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from lifelines) (0.5.0)\n",
      "Requirement already satisfied: formulaic>=0.2.2 in c:\\users\\harih\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from lifelines) (1.2.1)\n",
      "Requirement already satisfied: interface-meta>=1.2.0 in c:\\users\\harih\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from formulaic>=0.2.2->lifelines) (1.3.0)\n",
      "Requirement already satisfied: narwhals>=1.17 in c:\\users\\harih\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from formulaic>=0.2.2->lifelines) (1.24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\harih\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from formulaic>=0.2.2->lifelines) (4.10.0)\n",
      "Requirement already satisfied: wrapt>=1.0 in c:\\users\\harih\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from formulaic>=0.2.2->lifelines) (1.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\harih\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.0->lifelines) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\harih\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.0->lifelines) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\harih\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.0->lifelines) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\harih\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.0->lifelines) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\harih\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.0->lifelines) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\harih\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.0->lifelines) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\harih\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.0->lifelines) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\harih\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>=3.0->lifelines) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\harih\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=2.1->lifelines) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\harih\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=2.1->lifelines) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\harih\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install lifelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe280416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Found existing installation: llvmlite 0.45.1\n",
      "Uninstalling llvmlite-0.45.1:\n",
      "  Successfully uninstalled llvmlite-0.45.1\n",
      "Found existing installation: numba 0.62.1\n",
      "Uninstalling numba-0.62.1:\n",
      "  Successfully uninstalled numba-0.62.1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\harih\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\~lvmlite.libs'.\n",
      "You can safely remove it manually.\n",
      "WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\harih\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\~lvmlite'.\n",
      "You can safely remove it manually.\n",
      "WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\harih\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\~umba'.\n",
      "You can safely remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llvmlite\n",
      "  Using cached llvmlite-0.45.1-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting numba\n",
      "  Using cached numba-0.62.1-cp312-cp312-win_amd64.whl.metadata (2.9 kB)\n",
      "Collecting numpy<2.4,>=1.22 (from numba)\n",
      "  Using cached numpy-2.3.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Using cached llvmlite-0.45.1-cp312-cp312-win_amd64.whl (38.1 MB)\n",
      "Using cached numba-0.62.1-cp312-cp312-win_amd64.whl (2.7 MB)\n",
      "Using cached numpy-2.3.3-cp312-cp312-win_amd64.whl (12.8 MB)\n",
      "Installing collected packages: numpy, llvmlite, numba\n",
      "\n",
      "  Attempting uninstall: numpy\n",
      "\n",
      "    Found existing installation: numpy 1.26.4\n",
      "\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "    Uninstalling numpy-1.26.4:\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ---------------------------------------- 0/3 [numpy]\n",
      "   ------------- -------------------------- 1/3 [llvmlite]\n",
      "   ------------- -------------------------- 1/3 [llvmlite]\n",
      "   ------------- -------------------------- 1/3 [llvmlite]\n",
      "   ------------- -------------------------- 1/3 [llvmlite]\n",
      "   ------------- -------------------------- 1/3 [llvmlite]\n",
      "   ------------- -------------------------- 1/3 [llvmlite]\n",
      "   ------------- -------------------------- 1/3 [llvmlite]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   -------------------------- ------------- 2/3 [numba]\n",
      "   ---------------------------------------- 3/3 [numba]\n",
      "\n",
      "Successfully installed llvmlite-0.45.1 numba-0.62.1 numpy-2.3.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\harih\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\~0mpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\harih\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\~0mpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.3.3 which is incompatible.\n",
      "langchain 0.2.13 requires numpy<2.0.0,>=1.26.0; python_version >= \"3.12\", but you have numpy 2.3.3 which is incompatible.\n",
      "langchain-community 0.0.29 requires langchain-core<0.2.0,>=0.1.33, but you have langchain-core 0.2.30 which is incompatible.\n",
      "langchain-community 0.0.29 requires numpy<2,>=1, but you have numpy 2.3.3 which is incompatible.\n",
      "llama-index-readers-file 0.1.12 requires pypdf<5.0.0,>=4.0.1, but you have pypdf 5.2.0 which is incompatible.\n",
      "matplotlib 3.8.3 requires numpy<2,>=1.21, but you have numpy 2.3.3 which is incompatible.\n",
      "pandas 2.2.1 requires numpy<2,>=1.26.0; python_version >= \"3.12\", but you have numpy 2.3.3 which is incompatible.\n",
      "scikit-learn 1.4.1.post1 requires numpy<2.0,>=1.19.5, but you have numpy 2.3.3 which is incompatible.\n",
      "scipy 1.12.0 requires numpy<1.29.0,>=1.22.4, but you have numpy 2.3.3 which is incompatible.\n",
      "tensorflow-intel 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.3.3 which is incompatible.\n",
      "unstructured 0.15.1 requires numpy<2, but you have numpy 2.3.3 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall llvmlite numba -y\n",
    "%pip install llvmlite numba --force-reinstall"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
